{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "uois_sample_images.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanmed/uois/blob/master/uois_sample_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mKPJ3wPnyNge"
      },
      "outputs": [],
      "source": [
        "# Test the IOUS network on the container unloading data\n",
        "# Based on https://github.com/juanmed/uois/blob/master/uois_3D_example.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repository here\n",
        "!git clone https://github.com/juanmed/uois\n",
        "!mv uois/* ./\n",
        "!rm -rf uois"
      ],
      "metadata": {
        "id": "DR4WQJfyynPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependencies\n",
        "!pip install pypng matplotlib numpy opencv-python scikit-image gdown"
      ],
      "metadata": {
        "id": "mMcR3W8azTOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\" # TODO: Change this if you have more than 1 GPU\n",
        "\n",
        "import sys\n",
        "import json\n",
        "from time import time\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# My libraries. Ugly hack to import from sister directory\n",
        "import src.data_augmentation as data_augmentation\n",
        "import src.segmentation as segmentation\n",
        "import src.evaluation as evaluation\n",
        "import src.util.utilities as util_\n",
        "import src.util.flowlib as flowlib"
      ],
      "metadata": {
        "id": "wIDShWZJypF5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data processing functions\n",
        "def process_rgb(rgb_img):\n",
        "    \"\"\" Process RGB image\n",
        "            - random color warping\n",
        "    \"\"\"\n",
        "    rgb_img = rgb_img.astype(np.float32)\n",
        "    rgb_img = data_augmentation.standardize_image(rgb_img)\n",
        "    return rgb_img\n",
        "\n",
        "def process_depth(depth_img):\n",
        "    \"\"\" Process depth channel\n",
        "            TODO: CHANGE THIS\n",
        "            - change from millimeters to meters\n",
        "            - cast to float32 data type\n",
        "            - add random noise\n",
        "            - compute xyz ordered point cloud\n",
        "    \"\"\"\n",
        "\n",
        "    # millimeters -> meters\n",
        "    depth_img = (depth_img / 1000.).astype(np.float32)\n",
        "\n",
        "    # add random noise to depth\n",
        "    #if self.config['use_data_augmentation']:\n",
        "        #depth_img = data_augmentation.add_noise_to_depth(depth_img, self.config)\n",
        "        # depth_img = data_augmentation.dropout_random_ellipses(depth_img, self.config)\n",
        "\n",
        "    # Compute xyz ordered point cloud\n",
        "    params = {}\n",
        "    params['img_width'] = depth_img.shape[1] \n",
        "    params['img_height'] = depth_img.shape[0]\n",
        "    params['fov'] = 60\n",
        "    params['near'] = 0.01\n",
        "    xyz_img = util_.compute_xyz(depth_img, params)\n",
        "    #if self.config['use_data_augmentation']:\n",
        "    #    xyz_img = data_augmentation.add_noise_to_xyz(xyz_img, depth_img, self.config)\n",
        "\n",
        "    return xyz_img"
      ],
      "metadata": {
        "id": "FDxjQchEDODm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Depth Seeding Network Parameters"
      ],
      "metadata": {
        "id": "VAb6grRTzr7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dsn_config = {\n",
        "    \n",
        "    # Sizes\n",
        "    'feature_dim' : 64, # 32 would be normal\n",
        "\n",
        "    # Mean Shift parameters (for 3D voting)\n",
        "    'max_GMS_iters' : 10, \n",
        "    'epsilon' : 0.05, # Connected Components parameter\n",
        "    'sigma' : 0.02, # Gaussian bandwidth parameter\n",
        "    'num_seeds' : 200, # Used for MeanShift, but not BlurringMeanShift\n",
        "    'subsample_factor' : 5,\n",
        "    \n",
        "    # Misc\n",
        "    'min_pixels_thresh' : 500,\n",
        "    'tau' : 15.,\n",
        "    \n",
        "}"
      ],
      "metadata": {
        "id": "xFXrFWRIzk5G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Region Refinement Network parameters"
      ],
      "metadata": {
        "id": "YBmfvw3ZzuLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rrn_config = {\n",
        "    \n",
        "    # Sizes\n",
        "    'feature_dim' : 64, # 32 would be normal\n",
        "    'img_H' : 224,\n",
        "    'img_W' : 224,\n",
        "    \n",
        "    # architecture parameters\n",
        "    'use_coordconv' : False,\n",
        "    \n",
        "}"
      ],
      "metadata": {
        "id": "3TT0WPkxzxkD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UOIS-Net-3D Parameters"
      ],
      "metadata": {
        "id": "MoDloOOcz2bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uois3d_config = {\n",
        "    \n",
        "    # Padding for RGB Refinement Network\n",
        "    'padding_percentage' : 0.25,\n",
        "    \n",
        "    # Open/Close Morphology for IMP (Initial Mask Processing) module\n",
        "    'use_open_close_morphology' : True,\n",
        "    'open_close_morphology_ksize' : 9,\n",
        "    \n",
        "    # Largest Connected Component for IMP module\n",
        "    'use_largest_connected_component' : True,\n",
        "    \n",
        "}"
      ],
      "metadata": {
        "id": "BIl8I3efz3-x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download weights for DSN and RRN and untar"
      ],
      "metadata": {
        "id": "3q2QiqjB0QlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The weights are in a zip file here: https://drive.google.com/uc?export=download&id=1D-eaiOgFq_mg8OwbLXorgOB5lrxvmgQd\n",
        "import gdown \n",
        "url = 'https://drive.google.com/uc?id=1D-eaiOgFq_mg8OwbLXorgOB5lrxvmgQd'\n",
        "outfile = 'models.tar.gz'\n",
        "gdown.download(url, outfile, quiet=False)\n",
        "!mkdir models/\n",
        "!tar xvf models.tar.gz --directory models/"
      ],
      "metadata": {
        "id": "ScOVLzTv0TZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download sample unloader dataset"
      ],
      "metadata": {
        "id": "wC-PquPfCRHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample files at https://drive.google.com/file/d/1RnnfaxXDyYjcMk2b_6sWrlgaKxP92kuP/view?usp=sharing\n",
        "url = 'https://drive.google.com/uc?id=1RnnfaxXDyYjcMk2b_6sWrlgaKxP92kuP'\n",
        "outfile = 'unloading_rgbd.zip'\n",
        "gdown.download(url, outfile, quiet=False)\n",
        "!mkdir unloading_rgbd\n",
        "!unzip unloading_rgbd.zip -d unloading_rgbd/ > /dev/null"
      ],
      "metadata": {
        "id": "2-bcUbHzCVZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = '/content/models/' # TODO: change this to directory of downloaded models\n",
        "dsn_filename = checkpoint_dir + 'DepthSeedingNetwork_3D_TOD_checkpoint.pth'\n",
        "rrn_filename = checkpoint_dir + 'RRN_TOD_checkpoint.pth'\n",
        "uois3d_config['final_close_morphology'] = 'TableTop_v5' in rrn_filename\n",
        "uois_net_3d = segmentation.UOISNet3D(uois3d_config, \n",
        "                                     dsn_filename,\n",
        "                                     dsn_config,\n",
        "                                     rrn_filename,\n",
        "                                     rrn_config\n",
        "                                    )"
      ],
      "metadata": {
        "id": "XMOb-1H30DpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run on example OSD/OCID images"
      ],
      "metadata": {
        "id": "NDjgfDPw0I8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_images_dir = os.path.abspath('.') + '/example_images/'\n",
        "\n",
        "OSD_image_files = sorted(glob.glob(example_images_dir + '/OSD_*.npy'))\n",
        "OCID_image_files = sorted(glob.glob(example_images_dir + '/OCID_*.npy'))\n",
        "N = len(OSD_image_files) + len(OCID_image_files)\n",
        "\n",
        "rgb_imgs = np.zeros((N, 480, 640, 3), dtype=np.float32)\n",
        "xyz_imgs = np.zeros((N, 480, 640, 3), dtype=np.float32)\n",
        "label_imgs = np.zeros((N, 480, 640), dtype=np.uint8)\n",
        "\n",
        "for i, img_file in enumerate(OSD_image_files + OCID_image_files):\n",
        "    d = np.load(img_file, allow_pickle=True, encoding='bytes').item()\n",
        "    \n",
        "    # RGB\n",
        "    rgb_img = d['rgb']\n",
        "    print(\"RGB: \",rgb_img.shape)\n",
        "    rgb_imgs[i] = data_augmentation.standardize_image(rgb_img)\n",
        "\n",
        "    # XYZ\n",
        "    xyz_imgs[i] = d['xyz']\n",
        "    print(\"Depth : \",d['xyz'].shape)\n",
        "\n",
        "    # Label\n",
        "    label_imgs[i] = d['label']\n",
        "    \n",
        "batch = {\n",
        "    'rgb' : data_augmentation.array_to_tensor(rgb_imgs),\n",
        "    'xyz' : data_augmentation.array_to_tensor(xyz_imgs),\n",
        "}"
      ],
      "metadata": {
        "id": "wGQdAyvJ0J45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of images: {0}\".format(N))\n",
        "\n",
        "### Compute segmentation masks ###\n",
        "st_time = time()\n",
        "fg_masks, center_offsets, initial_masks, seg_masks = uois_net_3d.run_on_batch(batch)\n",
        "total_time = time() - st_time\n",
        "print('Total time taken for Segmentation: {0} seconds'.format(round(total_time, 3)))\n",
        "print('FPS: {0}'.format(round(N / total_time,3)))\n",
        "\n",
        "# Get results in numpy\n",
        "seg_masks = seg_masks.cpu().numpy()\n",
        "fg_masks = fg_masks.cpu().numpy()\n",
        "center_offsets = center_offsets.cpu().numpy().transpose(0,2,3,1)\n",
        "initial_masks = initial_masks.cpu().numpy()"
      ],
      "metadata": {
        "id": "7wRRV3EO3NYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_imgs = util_.torch_to_numpy(batch['rgb'].cpu(), is_standardized_image=True)\n",
        "total_subplots = 6\n",
        "\n",
        "fig_index = 1\n",
        "for i in range(N):\n",
        "    \n",
        "    num_objs = max(np.unique(seg_masks[i,...]).max(), np.unique(label_imgs[i,...]).max()) + 1\n",
        "    \n",
        "    rgb = rgb_imgs[i].astype(np.uint8)\n",
        "    depth = xyz_imgs[i,...,2]\n",
        "    seg_mask_plot = util_.get_color_mask(seg_masks[i,...], nc=num_objs)\n",
        "    gt_masks = util_.get_color_mask(label_imgs[i,...], nc=num_objs)\n",
        "    \n",
        "    images = [rgb, depth, seg_mask_plot, gt_masks]\n",
        "    titles = [f'Image {i+1}', 'Depth',\n",
        "              f\"Refined Masks. #objects: {np.unique(seg_masks[i,...]).shape[0]-1}\",\n",
        "              f\"Ground Truth. #objects: {np.unique(label_imgs[i,...]).shape[0]-1}\"\n",
        "             ]\n",
        "    util_.subplotter(images, titles, fig_num=i+1)\n",
        "    \n",
        "    # Run evaluation metric\n",
        "    eval_metrics = evaluation.multilabel_metrics(seg_masks[i,...], label_imgs[i])\n",
        "    print(f\"Image {i+1} Metrics:\")\n",
        "    print(eval_metrics)"
      ],
      "metadata": {
        "id": "dz955dId3UqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process unloading data"
      ],
      "metadata": {
        "id": "x824p0t-ClWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "color_image_folder = './unloading_rgbd/unloader_rgbd/color/'\n",
        "depth_image_folder = './unloading_rgbd/unloader_rgbd/depth/'\n",
        "\n",
        "color_images = os.listdir(color_image_folder)[:2] \n",
        "\n",
        "\n",
        "N = len(color_images)\n",
        "rgb_imgs = np.zeros((N, 480, 640, 3), dtype=np.float32)\n",
        "xyz_imgs = np.zeros((N, 480, 640, 3), dtype=np.float32)\n",
        "\n",
        "for i, img_file in enumerate(color_images):\n",
        "\n",
        "    # RGB\n",
        "    rgb_image = cv2.imread(os.path.join(color_image_folder,img_file), cv2.IMREAD_UNCHANGED)\n",
        "    rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)\n",
        "    rgb_image = cv2.resize(rgb_image,(640,480))\n",
        "    rgb_image = process_rgb(rgb_image)\n",
        "    print(\"RGB: \",rgb_image.shape)\n",
        "    rgb_imgs[i] = rgb_image\n",
        "\n",
        "\n",
        "    # XYZ\n",
        "    depth_image = cv2.imread(os.path.join(depth_image_folder,img_file), cv2.IMREAD_UNCHANGED)\n",
        "    depth_image = cv2.resize(depth_image, (640,480))\n",
        "    xyz_image = process_depth(depth_image)\n",
        "    print(\"Depth: \", xyz_image.shape)\n",
        "    xyz_imgs[i] = xyz_image\n",
        "    \n",
        "batch = {\n",
        "    'rgb' : data_augmentation.array_to_tensor(rgb_imgs),\n",
        "    'xyz' : data_augmentation.array_to_tensor(xyz_imgs),\n",
        "}\n",
        "\n",
        "### Compute segmentation masks ###\n",
        "st_time = time()\n",
        "fg_masks, center_offsets, initial_masks, seg_masks = uois_net_3d.run_on_batch(batch)\n",
        "total_time = time() - st_time\n",
        "print('Total time taken for Segmentation: {0} seconds'.format(round(total_time, 3)))\n",
        "print('FPS: {0}'.format(round(N / total_time,3)))\n",
        "\n",
        "# Get results in numpy\n",
        "seg_masks = seg_masks.cpu().numpy()\n",
        "fg_masks = fg_masks.cpu().numpy()\n",
        "center_offsets = center_offsets.cpu().numpy().transpose(0,2,3,1)\n",
        "initial_masks = initial_masks.cpu().numpy()"
      ],
      "metadata": {
        "id": "3POXHCJpRiND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_imgs = util_.torch_to_numpy(batch['rgb'].cpu(), is_standardized_image=True)\n",
        "total_subplots = 6\n",
        "\n",
        "fig_index = 1\n",
        "for i in range(N):\n",
        "    \n",
        "    num_objs = max(np.unique(seg_masks[i,...]).max(), np.unique(label_imgs[i,...]).max()) + 1\n",
        "    \n",
        "    rgb = rgb_imgs[i].astype(np.uint8)\n",
        "    depth = xyz_imgs[i,...,2]\n",
        "    seg_mask_plot = util_.get_color_mask(seg_masks[i,...], nc=num_objs)\n",
        "    #gt_masks = util_.get_color_mask(label_imgs[i,...], nc=num_objs)\n",
        "    \n",
        "    images = [rgb, depth, seg_mask_plot]#, gt_masks]\n",
        "    titles = [f'Image {i+1}', 'Depth',\n",
        "              f\"Refined Masks. #objects: {np.unique(seg_masks[i,...]).shape[0]-1}\",\n",
        "              #f\"Ground Truth. #objects: {np.unique(label_imgs[i,...]).shape[0]-1}\"\n",
        "             ]\n",
        "    util_.subplotter(images, titles, fig_num=i+1, plot_width=8)\n",
        "    \n",
        "    # Run evaluation metric\n",
        "    #eval_metrics = evaluation.multilabel_metrics(seg_masks[i,...], label_imgs[i])\n",
        "    #print(f\"Image {i+1} Metrics:\")\n",
        "    #print(eval_metrics)"
      ],
      "metadata": {
        "id": "zFNBHmKuTQXs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}